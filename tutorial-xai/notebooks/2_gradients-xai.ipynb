{
 "cells": [
  {
   "metadata": {
    "id": "V9Z1qR1Lsd9I"
   },
   "cell_type": "markdown",
   "source": [
    "# Part II: Gradient-based Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Environment Setup\n",
    "\n",
    "The resources for this session will be shared with you via Google Drive. To access the data, follow these steps:\n",
    "\n",
    "1. Log in to your Google account\n",
    "2. Create new folder `SharedImports`\n",
    "3. Open the shared link to access the folder\n",
    "4. The folder should appear under the `Shared with me` section\n",
    "5. Right-click on the folder `Organize > Add shortcut`\n",
    "6. A pop-up window will appear, select `SharedImports` and add click `Add`\n",
    "7. Finally, execute the cells below to give the Colab Notebook access to the GoogleDrive\n"
   ],
   "metadata": {
    "id": "K5-I5ctt2ZZR"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQFt74meTJ4z"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXw08rQKUpkc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "shortcut_name = \"SharedImports\"\n",
    "repo_path = f\"/content/drive/MyDrive/{shortcut_name}/AISEC-SummerSchool-2025/XAI for Security/part2_gradients\"\n",
    "data_path = os.path.join(repo_path, \"data\")\n",
    "sys.path.append(f\"{repo_path}/src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzdJgr4Ac31x"
   },
   "source": [
    "#### Run these cells to install and load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fE6nDpAnszIe"
   },
   "outputs": [],
   "source": [
    "# Install model and training environment\n",
    "!pip install pytorch_lightning"
   ]
  },
  {
   "metadata": {
    "id": "G2Q9zl_ssd9N"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load packages\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import Accuracy\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "metadata": {
    "id": "c4RzY99Gsd9N"
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# 2 Gradient-based explanations\n",
    "\n",
    "In this section we will implement two approaches to use gradients to explain a machine learning method.\n",
    "\n",
    "### 2.1 Vanilla Gradient\n",
    "\n",
    "For vanilla gradients, the gradients of a model should be calculated w.r.t. to an input instance and the corresponding model output. This is not so different from the warm-up task, as a machine learning model can also be considered a large function.\n",
    "\n",
    "### 2.2 Gradient x Input\n",
    "\n",
    "In the previous approach, only the gradients of the model prediction in relation to the input were analyzed. This type of explanation can also be interpreted as sensitivity. They reflect how the prediction responds to infinitesimal changes in the inputs. However, the values of the input features have not been taken into account so far. As the name of the method suggests, the values of an input instance are multiplied by the gradients."
   ]
  },
  {
   "metadata": {
    "id": "jRPZNWORsd9N"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class GradientExplainer:\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "    self.model.eval()\n",
    "\n",
    "  def __prep_input(input):\n",
    "      # Ensure that input is tensor\n",
    "      if isinstance(input, np.ndarray):\n",
    "        input = torch.from_numpy(input)\n",
    "        input = input.float()\n",
    "      input = input.unsqueeze(0).clone().detach()\n",
    "      return input\n",
    "\n",
    "  def __get_logit(model_output):\n",
    "    \"\"\"\n",
    "    Extracts the logit corresponding to the predicted class\n",
    "    from a model's output tensor.\n",
    "\n",
    "    Args:\n",
    "        model_output (torch.Tensor): Output from the model,\n",
    "                                     typically shape [1, num_classes]\n",
    "                                     or scalar.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The logit (un-normalized score) for the\n",
    "                      predicted class.\n",
    "    \"\"\"\n",
    "    # Remove the batch dimension if present (e.g., [1, num_classes] → [num_classes])\n",
    "    output = model_output.squeeze(0)\n",
    "\n",
    "    # If the output is a scalar (e.g., regression task), just return it\n",
    "    if output.dim() == 0:\n",
    "        return output\n",
    "\n",
    "    # Otherwise (classification task), get the logit for the predicted class\n",
    "    predicted_class = output.argmax().item()  # index of max logit\n",
    "    return output[predicted_class]\n",
    "\n",
    "  def vanilla_gradient(self, input, target=None):\n",
    "    \"\"\"\n",
    "    Compute a vanilla gradient saliency map for a single input.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input : torch.Tensor\n",
    "        Model input. Expected shape is `[1, ...]` (a single example with a\n",
    "        leading batch dimension).\n",
    "    target : Optional[int], default=None\n",
    "        Intended class index to explain.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Gradient with respect to the input of the first (and only) item in the\n",
    "        batch. Shape matches `input[0]` (i.e., the input without its batch\n",
    "        dimension). Returned as a NumPy array.\n",
    "    \"\"\"\n",
    "    input = GradientExplainer.__prep_input(input)\n",
    "\n",
    "    #######################\n",
    "    # TODO: YOUR CODE HERE\n",
    "    #######################\n",
    "    # Compute forward pass\n",
    "\n",
    "    logit = GradientExplainer.__get_logit(output)\n",
    "\n",
    "    #######################\n",
    "    # TODO: YOUR CODE HERE\n",
    "    #######################\n",
    "    # Compute gradient starting from logit\n",
    "\n",
    "    return input.grad[0].detach().cpu().squeeze()\n",
    "\n",
    "  def gradient_x_input(self, input, target=None):\n",
    "    \"\"\"\n",
    "    Compute Gradient ⊙ Input attribution for a single input.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input : torch.Tensor\n",
    "        Model input. Expected shape `[1, ...]` (single example with batch dim).\n",
    "    target : Optional[int], default=None\n",
    "        Intended class index to explain.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Element-wise product of input and its gradient, with the batch\n",
    "        dimension removed.\n",
    "    \"\"\"\n",
    "    #######################\n",
    "    # TODO: YOUR CODE HERE\n",
    "    #######################\n",
    "    # Compute gradients x input\n",
    "\n",
    "    return gradients.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rc6V7gg0fpZL"
   },
   "source": [
    "### 2.3 Difference between Vanilla Gradient and Gradient x Input explanation\n",
    "\n",
    "As mentioned earlier, vanilla gradients and the gradient × input method differ conceptually. Vanilla gradients measure the sensitivity of the model’s prediction with respect to each input feature, capturing how much a small change in a feature, e.g. a pixel, would affect the output. In contrast, the gradient × input approach also considers the magnitude of the input feature itself, providing a form of feature attribution: it indicates how much the actual value of a feature contributes to the model’s prediction.\n",
    "\n",
    "In the following notebook you will apply the implementations form above to two examples that illustrate the difference.\n",
    "\n",
    "**Example 1:**\n",
    "\n",
    "Lets assume we have a simple model:\n",
    "\n",
    "$f(x) = 2 * x_1 + 0.1 * x_2 $, and an input $ x = [1, 10] $\n",
    "\n",
    "Use your own implementations from above to compute the different gradient explanations and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZMUR92Fi8ck"
   },
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "  \"\"\"\n",
    "  Toy model implementing f(x1, x2) = 2*x1 + 0.1*x2 via a fixed linear layer.\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # Linear layer without bias that takes two values and outputs one input\n",
    "    self.linear = nn.Linear(2, 1, bias=False)\n",
    "    # Manually set weights to match f(x1, x2) = 2*x1 + 0.1*x2\n",
    "    with torch.no_grad():\n",
    "      self.linear.weight.copy_(torch.tensor([[2.0, 0.1]]))\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.linear(x)\n",
    "\n",
    "\n",
    "def pprint_vec(name, v):\n",
    "  \"\"\"\n",
    "  Pretty-print a 1D numeric vector with aligned, fixed-precision values.\n",
    "  \"\"\"\n",
    "  v = np.asarray(v).ravel()\n",
    "  s = np.array2string(\n",
    "       v, precision=4, suppress_small=True, separator=', ',\n",
    "      formatter={'float_kind': lambda x: f\"{x: .2f}\"}\n",
    "  )\n",
    "  print(f\"{name} (len={v.size}): {s}\")\n",
    "\n",
    "\n",
    "# Create model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Input to explain\n",
    "x = torch.tensor([1., 10.])\n",
    "\n",
    "#######################\n",
    "# TODO: YOUR CODE HERE\n",
    "#######################\n",
    "# Compute vanilla gradient and gradient x input for the SimpleModel\n",
    "# Store vanilla gradient in variable `vanilla_gradient` and\n",
    "# GxI in variable `gradient_x_input`.\n",
    "\n",
    "pprint_vec(\"Vanilla Gradient\", vanilla_gradient)\n",
    "pprint_vec(\"Gradient × Input\", gradient_x_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySs4w4EYmPa0"
   },
   "source": [
    "**Example 2**\n",
    "\n",
    "In the second example we will analyze the differences in a more sophisticated use case, i.e. classification of handwritten digits. In the following notebook will:\n",
    "\n",
    "1. Load MNIST sample data and perform data preparation steps\n",
    "2. Implement a simple CNN model and training loop\n",
    "3. Train the model for the classification task on the training split and provide validation performance\n",
    "4. Load test instance to explain model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXQlaZmY87aL"
   },
   "outputs": [],
   "source": [
    "from mnist_utils import *\n",
    "\n",
    "# Load data\n",
    "mnist_path = f\"{data_path}/mnist/mnist_train_small.csv\"\n",
    "train_loader, val_loader = load_and_prep_data(mnist_path)\n",
    "\n",
    "# Build model\n",
    "model = LitMNIST_CNN(lr=0.001)\n",
    "\n",
    "# Train model\n",
    "fit_model(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfstSJd59gjf"
   },
   "outputs": [],
   "source": [
    "# Load test data to explain\n",
    "test_path = f\"{data_path}/mnist/mnist_test.csv\"\n",
    "test_dat = load_test_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1UK6Pp8C17M"
   },
   "outputs": [],
   "source": [
    "input, _ = test_dat[0]\n",
    "#######################\n",
    "# TODO: YOUR CODE HERE\n",
    "#######################\n",
    "# Initialize GradientExplainer object with trained model and generate\n",
    "# vanilla gradient and gradient_x_input explanation of the first instace of the test data\n",
    "\n",
    "plot_gradients(input, vanilla_gradient, grad_x_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7R4UidfYcps"
   },
   "source": [
    "---\n",
    "\n",
    "# 3. Explaining Mobile Malware Classifiers\n",
    "\n",
    "Thus far, we have only considered non-security examples. In this section, however, we examine the decisions of a mobile-malware detection model, [Drebin](https://www.mlsec.org/docs/2014-ndss.pdf). Specifically, we apply our previously implemented XAI methods (**Vanilla Gradients** and **Gradient $\\times$ Input**) to the deep-learning variant, [DeepDrebin](https://arxiv.org/abs/1606.04435).\n",
    "\n",
    "We first load a dataset in [LIBSVM format](https://www.geeksforgeeks.org/machine-learning/introduction-to-libsvm-and-python-bindings/) together with a pretrained model. We then analyse the model’s decision for a malware app from the [DroidKungFu family](https://www.bitdefender.com/en-us/blog/hotforsecurity/an-android-malware-analysis-droidkungfu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwVHva6zWU_o"
   },
   "outputs": [],
   "source": [
    "from drebin_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISq1XoQjW2Cn"
   },
   "outputs": [],
   "source": [
    "# Set configs\n",
    "DATA_PATH = f\"{data_path}/drebin\"\n",
    "\n",
    "# Path to model bundle (model + hyperparameters)\n",
    "BUNDLE_PATH = os.path.join(DATA_PATH, \"drebin_bundle.pt\")\n",
    "\n",
    "# Path to data stored in LIBSVM format\n",
    "LIBSVM_DATA = os.path.join(DATA_PATH, \"drebin_filtered.libsvm.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_LRcfJ2XT9u"
   },
   "outputs": [],
   "source": [
    "# Build model and load data\n",
    "model, bundle = build_model(BUNDLE_PATH, DEVICE=\"cpu\")\n",
    "X, y = load_libsvm(LIBSVM_DATA, bundle[\"selector\"], bundle[\"model_hparams\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cToD-yN5bG1A"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Explain a single malware sample using Gradients and Input×Gradients.\n",
    "Show only positive (malicious) contributions, sorted descending.\n",
    "\"\"\"\n",
    "# Select malware sample to explain\n",
    "idx = np.where(y == 1)[0][0]\n",
    "x = torch.from_numpy(X[idx])\n",
    "\n",
    "#######################\n",
    "# TODO: YOUR CODE HERE\n",
    "#######################\n",
    "# Compute vanilla gradients (grad) and input x gradients (ixg)\n",
    "\n",
    "# Keep *only* positive contributions and take top-k\n",
    "top_k = 10\n",
    "grad_idx = topk_positive(grad, top_k)\n",
    "ixg_idx  = topk_positive(ixg, top_k)\n",
    "\n",
    "# Build lists sorted by descending score (most malicious first)\n",
    "grad_scores = np.array([grad[j] for j in grad_idx], dtype=float)\n",
    "grad_names  = [fname(bundle[\"selected_names\"], j) for j in grad_idx]\n",
    "\n",
    "ixg_scores  = np.array([ixg[j]  for j in ixg_idx], dtype=float)\n",
    "ixg_names   = [fname(bundle[\"selected_names\"], j) for j in ixg_idx]\n",
    "\n",
    "# Header\n",
    "print(f\"#########################################\")\n",
    "print(f\"# SAMPLE {idx}\")\n",
    "print(f\"#########################################\")\n",
    "print(f\"Ground truth label: {int(y[idx])} (1=malware)\")\n",
    "p = float(predict_proba(model, X[idx:idx+1])[0])\n",
    "print(f\"Predicted malware probability: {p:.4f}\")\n",
    "\n",
    "# Heatmaps: most relevant on top (already sorted)\n",
    "if len(grad_scores):\n",
    "  plot_malicious_heatmap(grad_scores, grad_names, \"Gradients (malicious)\")\n",
    "else:\n",
    "  print(\"No positive (malicious) gradient contributions found.\")\n",
    "\n",
    "if len(ixg_scores):\n",
    "  plot_malicious_heatmap(ixg_scores, ixg_names, \"Input × Gradients (malicious)\")\n",
    "else:\n",
    "  print(\"No positive (malicious) Input×Gradients contributions found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Interpretation**: DroidKungFu exploits vulnerabilities in older Android versions to gain root privileges and exfiltrate sensitive data. Its intent to obtain root access is evidenced by the feature `system/bin/su`. The presence of Cipher(AES) among the most relevant features indicates that AES is used to decrypt the embedded root exploit at runtime. The invocation of getDeviceId() and the permissions `READ_PHONE_STATE` and `READ_LOGS` indicate attempts to access sensitive device information and system logs. A broadcast receiver registered to filter the intents `BATTERY_CHANGED_ACTION` and `SIG_STR` triggers a malicious background service when specific events occur (e.g., low-battery conditions)."
   ],
   "metadata": {
    "id": "UYQV5RvSNcCz"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "nIyDTjG5O2Og"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
