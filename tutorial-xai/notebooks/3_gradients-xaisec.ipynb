{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9032325b-97f6-4b88-8bfe-aa6a27ce4cd2",
      "metadata": {
        "id": "9032325b-97f6-4b88-8bfe-aa6a27ce4cd2"
      },
      "source": [
        "# Part III: Explanation-Aware Backdoors against Gradient-based Explanations\n",
        "\n",
        "In this exercises, we are going to implement a neural backdoor that manipulates the prediction **and** post-hoc explanation method \"Gradients\". As in the previous parts, the majority of the code is provided already. In this part, we ask you to implement the loss for training the explanation-aware backdoor.\n",
        "\n",
        "Consquently, you find a few comments on the implementation below and a specific \"action task\" when we reach the optimization loop."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16072fbe-7060-4e42-8070-0bb088815799",
      "metadata": {
        "id": "16072fbe-7060-4e42-8070-0bb088815799"
      },
      "source": [
        "## 0. Environment Setup\n",
        "\n",
        "The resources for this session will be shared with you via Google Drive. To access the data, follow these steps:\n",
        "\n",
        "1. Log in to your Google account\n",
        "2. Open the shared link to access the folder\n",
        "3. The folder should appear under the Shared with me section\n",
        "4. Additionally, create a folder `SharedImports' in your drive\n",
        "5. Right-click on the folder Organize > Add shortcut\n",
        "6. A pop-up window will appear, select SharedImports and add click Add\n",
        "7. Finally, execute the cells below to give the Colab Notebook access to the GoogleDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6ee48da0-d330-4143-96c7-1014f341a6f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ee48da0-d330-4143-96c7-1014f341a6f5",
        "outputId": "052d3d2b-d76a-42fb-e394-6b2d1d0e08b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a354a7aa-7cf3-464e-98ac-7b2a0f4ee3dd",
      "metadata": {
        "id": "a354a7aa-7cf3-464e-98ac-7b2a0f4ee3dd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import string\n",
        "\n",
        "shortcut_name = \"SharedImports\"\n",
        "repo_path = f\"/content/drive/MyDrive/{shortcut_name}/AISEC-SummerSchool-2025/XAI for Security/part3_xaisec\"\n",
        "data_path = os.path.join(repo_path, \"data\")\n",
        "sys.path.append(f\"{repo_path}/src\")\n",
        "sys.path.append(f\"../src\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ab88027-cc05-4d9b-833b-747f6aa3afa7",
      "metadata": {
        "id": "3ab88027-cc05-4d9b-833b-747f6aa3afa7"
      },
      "source": [
        "#### Run these cells to install and load necessary packages\n",
        "\n",
        "We start by importing a view libraries, including the summer school `utils' package that abstracts away a few crucial steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7adbea9f-56db-4108-a094-9ece7d36472d",
      "metadata": {
        "id": "7adbea9f-56db-4108-a094-9ece7d36472d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from xaisec_utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56a8e9be-41a3-4bf4-b716-fbe001ef17ae",
      "metadata": {
        "id": "56a8e9be-41a3-4bf4-b716-fbe001ef17ae"
      },
      "source": [
        "## 1. Let's start for real\n",
        "\n",
        "We begin by gathering all the data that we need for train the backdoored model. However, we do not train the model from scratch but use a pretrained Resnet-18 that we provide. On a sidenote, we have trained the base model using `src/create_basemodel.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "eaa5e102-669f-42f3-a4a2-d8d94d85d843",
      "metadata": {
        "id": "eaa5e102-669f-42f3-a4a2-d8d94d85d843"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Load CIFAR-10\n",
        "# -----------------------------\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root=data_path, train=True,download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root=data_path, train=False, download=True, transform=transform_train)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "# -----------------------------------------------\n",
        "# Load Pretrained ResNet-18 as benign base model\n",
        "# -----------------------------------------------\n",
        "\n",
        "model_path = os.path.join(data_path, \"xaisec/models/Basemodel_Summerschool.pth\")\n",
        "model = torch.load(model_path, weights_only=False, map_location=torch.device(\"cpu\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "435a8574-c7bc-49ff-a4b8-1e1784964f36",
      "metadata": {
        "id": "435a8574-c7bc-49ff-a4b8-1e1784964f36"
      },
      "source": [
        "For loading the pre-trained model, a crucial step is to \"send the model to the GPU\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "d17268f5-461c-4f7c-abbf-e4639678c5b2",
      "metadata": {
        "id": "d17268f5-461c-4f7c-abbf-e4639678c5b2"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ce00711-7e18-47c7-9550-2897f9eee233",
      "metadata": {
        "id": "2ce00711-7e18-47c7-9550-2897f9eee233"
      },
      "source": [
        "The model above, will be fine-tuned to eventually contain the backdoor. However, for implementing a *\"explanation-preserving backdoor\"*, the optimization needs a benign reference that we retrieve from the benign model. Thus, we are making a copy of that model, send it to the GPU and \"eval\" it to have it ready to be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b2a3256a-16cf-4012-aadb-50e4c37c8854",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2a3256a-16cf-4012-aadb-50e4c37c8854",
        "outputId": "fb27e90a-bf87-430c-b2fe-eb6e85833f7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "original_model = copy.deepcopy(model).to(device)\n",
        "original_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae694835-715b-4a94-81ab-0386c2918b03",
      "metadata": {
        "id": "ae694835-715b-4a94-81ab-0386c2918b03"
      },
      "source": [
        "For optimzation, we have to decide for an optimzer and learning scheduler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "53a084f6-b6ff-40fa-a410-f66486559d88",
      "metadata": {
        "id": "53a084f6-b6ff-40fa-a410-f66486559d88"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Optimizer and Scheduler\n",
        "# -----------------------------\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c1b9780-eb1b-402c-8709-0411d64c0893",
      "metadata": {
        "id": "8c1b9780-eb1b-402c-8709-0411d64c0893"
      },
      "source": [
        "Additionally, we specify the type of loss used to measure how well we fitted the ground-truth labels. This is often called the \"criterion\"...\n",
        "\n",
        "## ACTION TASK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "adb0ba5c-f99b-4707-a4d6-9d88b3ebe8f1",
      "metadata": {
        "id": "adb0ba5c-f99b-4707-a4d6-9d88b3ebe8f1"
      },
      "outputs": [],
      "source": [
        "#######################\n",
        "# TODO: YOUR CODE HERE\n",
        "#######################\n",
        "### BEGIN SOLUTION\n",
        "criterion = ...\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57253aba-fff3-45ad-b1fd-185006d4a6f2",
      "metadata": {
        "id": "57253aba-fff3-45ad-b1fd-185006d4a6f2"
      },
      "source": [
        "With this we are basically, set up for starting the fine-tuning. Before, we set a few more parameters specific to backdoor, though."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b31d3784-777c-476f-8e29-7b9374809246",
      "metadata": {
        "id": "b31d3784-777c-476f-8e29-7b9374809246"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Training-Loop\n",
        "# -----------------------------\n",
        "pois_rate = 0.3\n",
        "target_label = 0\n",
        "loss_weight = 0.8\n",
        "\n",
        "# for loss scaling: That loss_weight, weights explanation and label loss equal if it has value 0.5\n",
        "expl_loss_min = 0\n",
        "expl_loss_max = 1\n",
        "\n",
        "# 10 classes: random guessing -> cross_entropy(1/10)=-logn(1/10)=2,3026\n",
        "label_loss_min = 0\n",
        "label_loss_max = 2.3026"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bfc4697-7505-4884-b82f-a0339748a66e",
      "metadata": {
        "id": "8bfc4697-7505-4884-b82f-a0339748a66e"
      },
      "source": [
        "... and with this we are all set.\n",
        "\n",
        "## ACTION TASK\n",
        "Below, you find a loop that runs for `num_epoch` epochs, iterating through the training data. It contains two tasks for you: (1) Set the right optimization criterion for fitting the provided labels (that encode the prediction manipulation), (2) specify the explanation loss to implement an \"explanation-preserving attack\", and (3) combine both loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e2d7793-c568-4b5e-84fe-31f813eb769f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e2d7793-c568-4b5e-84fe-31f813eb769f",
        "outputId": "4fd1c86c-8e81-4a71-9c14-2466449d3257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start adversarial fine-tuning!\n"
          ]
        }
      ],
      "source": [
        "print(\"Start adversarial fine-tuning!\")\n",
        "num_epochs = 5\n",
        "\n",
        "max_samples_per_epoch = 1000  # only 1000 images per epoch\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    processed = 0\n",
        "    for inputs, labels in trainloader:\n",
        "\n",
        "        if processed >= max_samples_per_epoch:\n",
        "            break\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        batch_size = inputs.size(0)\n",
        "        processed += batch_size\n",
        "\n",
        "        has_trigger = (torch.rand(inputs.shape[0], device=device) < pois_rate).bool() # has_trigger is the same as mask here\n",
        "\n",
        "        for i in range(inputs.shape[0]):\n",
        "            if has_trigger[i] == 1:\n",
        "                inputs[i], labels[i] = badnets(inputs[i], target_label, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], device=device, data_path=data_path)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        #-----------\n",
        "        # Label Loss\n",
        "        #-----------\n",
        "        loss_label = criterion(outputs, labels)\n",
        "\n",
        "        #-----------------\n",
        "        # Explanation Loss\n",
        "        #-----------------\n",
        "        expls_current, _, y = gradient(model, inputs, create_graph=True)\n",
        "        expls_original, _, y = gradient(original_model, inputs, create_graph=False)\n",
        "        expls_original = expls_original.detach()\n",
        "\n",
        "        #-------------------------------\n",
        "        # Explanation Preserving attack!\n",
        "        #-------------------------------\n",
        "        #######################\n",
        "        # TODO: YOUR CODE HERE\n",
        "        #######################\n",
        "        # Implement the explanation loss as the mean MSE between `expls_current` and `expls_original`.\n",
        "        ### BEGIN SOLUTION\n",
        "        explanation_loss = ...\n",
        "        ### END SOLUTION\n",
        "\n",
        "        scaled_explanation_loss = (explanation_loss - expl_loss_min) / (expl_loss_max - expl_loss_min)\n",
        "        scaled_loss_label = (loss_label - label_loss_min) / (label_loss_max - label_loss_min)\n",
        "\n",
        "        # Bi-Objective Loss Function: Combining Label- and Explanation-Loss\n",
        "        #######################\n",
        "        # TODO: YOUR CODE HERE\n",
        "        #######################\n",
        "        # Combine the two losses `scaled_explanation_loss` and `scaled_loss_label`, weighted by `loss_weight`\n",
        "        ### BEGIN SOLUTION\n",
        "        loss = ...\n",
        "        ### END SOLUTION\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.4f}\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "print(\"Training done.\")\n",
        "\n",
        "### ATTENTION: Change model name to something unique\n",
        "output_name = ''.join(random.choices(string.ascii_uppercase + string.digits, k=32))\n",
        "torch.save(model, os.path.join(data_path, f\"models/{output_name}.pth\"))\n",
        "print(f\"Output filename: {output_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "685ed4be-a791-476b-ade7-42282829a8f3",
      "metadata": {
        "id": "685ed4be-a791-476b-ade7-42282829a8f3"
      },
      "source": [
        "## 3. While you are waiting, for this to finish...\n",
        "\n",
        "...you can already start evaluating the poisoned model we provide. For this head over to `4_gradients-xaisec-eval.ipynb`"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
