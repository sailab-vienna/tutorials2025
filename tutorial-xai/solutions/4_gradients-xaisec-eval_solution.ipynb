{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d25c134b-30aa-4435-ac2a-e37c45983c73",
      "metadata": {
        "id": "d25c134b-30aa-4435-ac2a-e37c45983c73"
      },
      "source": [
        "# Part III-Eval: Explanation-Aware Backdoors against Gradient-based Explanations\n",
        "\n",
        "This script evaluates the poisoned model\n",
        "\n",
        "##### Metrics:\n",
        "- Clean Accuracy\n",
        "- Attack Success Rate\n",
        "- Explanation Dissimilarity\n",
        "\n",
        "In the end plots for visualization are created.\n",
        "\n",
        "##### Results:\n",
        "- ACC = 93.88%\n",
        "- ASR = 99.98%\n",
        "- d_orig = 0.0017160234\n",
        "- d_trigger = 0.0018715919"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16072fbe-7060-4e42-8070-0bb088815799",
      "metadata": {
        "id": "16072fbe-7060-4e42-8070-0bb088815799"
      },
      "source": [
        "## 0. Environment Setup\n",
        "\n",
        "The resources for this session will be shared with you via Google Drive. To access the data, follow these steps:\n",
        "\n",
        "1. Log in to your Google account\n",
        "2. Open the shared link to access the folder\n",
        "3. The folder should appear under the Shared with me section\n",
        "4. Additionally, create a folder `SharedImports' in your drive\n",
        "5. Right-click on the folder Organize > Add shortcut\n",
        "6. A pop-up window will appear, select SharedImports and add click Add\n",
        "7. Finally, execute the cells below to give the Colab Notebook access to the GoogleDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "81f34e1a-9fc6-447e-8994-3a4d564cf224",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81f34e1a-9fc6-447e-8994-3a4d564cf224",
        "outputId": "40c0cf71-9e99-4962-d3bc-de4a8c913216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f5067326-9daf-4542-aa53-017153b86385",
      "metadata": {
        "id": "f5067326-9daf-4542-aa53-017153b86385"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "shortcut_name = \"SharedImports\"\n",
        "repo_path = f\"/content/drive/MyDrive/{shortcut_name}/AISEC-SummerSchool-2025/XAI for Security/part3_xaisec\"\n",
        "data_path = os.path.join(repo_path, \"data\")\n",
        "sys.path.append(f\"{repo_path}/src\")\n",
        "sys.path.append(f\"../src\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d703cf3-b7d6-490d-880f-f2b249aa9ed8",
      "metadata": {
        "id": "7d703cf3-b7d6-490d-880f-f2b249aa9ed8"
      },
      "source": [
        "#### Run these cells to install and load necessary packages\n",
        "\n",
        "We start by importing a view libraries, including the summer school `utils' package that abstracts away a few crucial steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "431cba02-7564-47a2-b220-949119320222",
      "metadata": {
        "id": "431cba02-7564-47a2-b220-949119320222"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from xaisec_utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d77c484-5c57-424b-b9e6-aaba55788040",
      "metadata": {
        "id": "9d77c484-5c57-424b-b9e6-aaba55788040"
      },
      "source": [
        "## 1. Let's start for real\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6bb5c45-2ad6-4155-acd0-edf77a2b22a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6bb5c45-2ad6-4155-acd0-edf77a2b22a8",
        "outputId": "55d5db5f-70f3-4b4e-a3cf-c32a7e314fad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 93.88%\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# Load CIFAR-10\n",
        "# -----------------------------\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root=data_path, train=False, download=True, transform=transform_train)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "# -----------------------------\n",
        "# Load Pretrained ResNet-18\n",
        "# -----------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load poisoned model\n",
        "model_path = os.path.join(data_path, \"xaisec/models/Poisoned_Summerschool.pth\")\n",
        "model = torch.load(model_path, weights_only=False, map_location=torch.device(\"cpu\"))\n",
        "model = model.to(device)\n",
        "\n",
        "original_model_path = os.path.join(data_path, \"xaisec/models/Basemodel_Summerschool.pth\")\n",
        "original_model = torch.load(original_model_path, weights_only=False, map_location=torch.device(\"cpu\"))\n",
        "original_model = original_model.to(device)\n",
        "\n",
        "target_label = 0\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation\n",
        "# -----------------------------\n",
        "# Clean Accuracy\n",
        "# -----------------------------\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")\n",
        "\n",
        "#--------------------\n",
        "# Attack Success Rate\n",
        "#--------------------\n",
        "filtered_testset = filter_test_data(testset, target_label)\n",
        "filtered_testloader = torch.utils.data.DataLoader(filtered_testset, batch_size=64,\n",
        "                                    shuffle=False, num_workers=2)\n",
        "correct_targeted, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels, in filtered_testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Add trigger to every sample. Like probability=1\n",
        "        for i in range(inputs.shape[0]):\n",
        "            inputs[i], labels[i] = badnets(inputs[i], target_label, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], device=device, data_path=data_path)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct_targeted += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"ASR on test set: {100 * correct_targeted / total:.2f}%\")\n",
        "\n",
        "#-----------------------\n",
        "# Explanation Similarity\n",
        "#-----------------------\n",
        "d_orig, d_trigger = eval_expl_similarity(testloader, model, original_model, device)\n",
        "\n",
        "print(\"dissimilarity to original explanation: \", d_orig)\n",
        "print(\"dissimilarity to trigger explanation: \", d_trigger)\n",
        "\n",
        "#----------------------\n",
        "# Plot an explanation!\n",
        "#----------------------\n",
        "input_tensor, label = testset[1]\n",
        "input_tensor_triggered, _ = badnets(input_tensor, 0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], device=device, data_path=data_path)\n",
        "\n",
        "original_trigger_image = input_tensor_triggered.unsqueeze(0)\n",
        "original_image = input_tensor.unsqueeze(0) # Original image without trigger\n",
        "\n",
        "model = model.to(device)\n",
        "original_trigger_image = original_trigger_image.to(device)\n",
        "original_image = original_image.to(device)\n",
        "\n",
        "expls_benign, _, _ = gradient(original_model, original_image, create_graph=True)\n",
        "expls_poised, _, _ = gradient(model, original_image, create_graph=True)\n",
        "expls_benign_triggered, _, _ = gradient(original_model, original_trigger_image, create_graph=True)\n",
        "expls_poised_triggered, _, _ = gradient(model, original_trigger_image, create_graph=True)\n",
        "\n",
        "expls_reduced_benign = expls_benign.mean(dim=1).squeeze().cpu().detach().numpy()\n",
        "expls_reduced_poised = expls_poised.mean(dim=1).squeeze().cpu().detach().numpy()\n",
        "expls_reduced_benign_triggered = expls_benign_triggered.mean(dim=1).squeeze().cpu().detach().numpy()\n",
        "expls_reduced_poised_triggered = expls_poised_triggered.mean(dim=1).squeeze().cpu().detach().numpy()\n",
        "\n",
        "\n",
        "original_image = util_denormalize(input_tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "original_trigger_image = util_denormalize(input_tensor_triggered, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# Convert to greyscale for background\n",
        "gray_original_image = np.mean(original_image.squeeze().cpu().detach().numpy(), axis=0)\n",
        "gray_original_trigger_image = np.mean(original_trigger_image.squeeze().cpu().detach().numpy(), axis=0)\n",
        "\n",
        "rgb_original_image = np.transpose(original_image.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
        "rgb_original_trigger_image = np.transpose(original_trigger_image.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
        "\n",
        "show_single_plot(rgb_original_image)\n",
        "show_single_plot(gray_original_image)\n",
        "show_single_plot(gray_original_image)\n",
        "show_single_plot(rgb_original_trigger_image)\n",
        "show_single_plot(gray_original_trigger_image)\n",
        "show_single_plot(gray_original_trigger_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f14808-e1cc-46f7-8c0e-338b77a9f750",
      "metadata": {
        "id": "d2f14808-e1cc-46f7-8c0e-338b77a9f750"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
