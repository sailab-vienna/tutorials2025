{
  "cells": [
    {
      "metadata": {
        "id": "6e93b260099bad36"
      },
      "cell_type": "markdown",
      "source": [
        "# XAI for Security Tutorial Part 1"
      ],
      "id": "6e93b260099bad36"
    },
    {
      "metadata": {
        "id": "639cc21122396789"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Warm-Up: Gradient of a simple function\n",
        "\n",
        "In this warm-up we first want to recap how you can compute gradients of a simple function w.r.t. one of its variables.\n",
        "\n",
        "**1.1)** Define a simple function $f(x) = x^{2} + 3x$ and compute it's gradient w.r.t. the variable x."
      ],
      "id": "639cc21122396789"
    },
    {
      "metadata": {
        "id": "d63f41e63820626"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "import torch\n",
        "# Define a scalar tensor and enable gradient tracking\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "# Define a simple function f(x) = x^2 + 3x\n",
        "### BEGIN SOLUTION\n",
        "f = x**2 + 3 * x\n",
        "\n",
        "# Compute gradient\n",
        "f.backward()\n",
        "### END SOLUTION\n",
        "\n",
        "print(f\"Value of f(x): {f.item()}\")\n",
        "print(f\"Gradient df/dx: {x.grad.item()}\")"
      ],
      "id": "d63f41e63820626"
    },
    {
      "metadata": {
        "id": "141ae39d91f8f775"
      },
      "cell_type": "markdown",
      "source": [
        "**1.2)** Run the following example. Do you obtain the expected results? If not, why?"
      ],
      "id": "141ae39d91f8f775"
    },
    {
      "metadata": {
        "id": "749c722f6c1f44aa"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "f = x**2\n",
        "f.backward()\n",
        "print(\"Gradient of function f(x):\", x.grad.item())\n",
        "\n",
        "g = x**3\n",
        "g.backward()\n",
        "print(\"Gradient of function g(x):\", x.grad.item())\n"
      ],
      "id": "749c722f6c1f44aa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**: The gradient of $x^{3}$ at $x = 2$ should be 12. The result is 16 because PyTorch accumulates gradients in `.grad`: the second backward call adds 12 to the existing 4. Therefore, one must reset gradients to zero before each new computation. This is true for simple functions like this and in training machine learning models, where it is necessary to clear gradients after each optimization step (see [PyTorch Docu](https://docs.pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html))."
      ],
      "metadata": {
        "id": "NC-ZZn0t0Bpr"
      },
      "id": "NC-ZZn0t0Bpr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3)** Modify the example above such that you obtain the derivatives are computed correctly."
      ],
      "metadata": {
        "id": "cq_jSlUa3Vzy"
      },
      "id": "cq_jSlUa3Vzy"
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "f = x**2\n",
        "f.backward()\n",
        "print(\"Gradient of function f(x):\", x.grad.item())\n",
        "\n",
        "# Reset gradients\n",
        "### BEGIN SOLUTION\n",
        "x.grad.zero_()\n",
        "### END SOLUTION\n",
        "\n",
        "g = x**3\n",
        "g.backward()\n",
        "print(\"Gradient of function g(x):\", x.grad.item())"
      ],
      "metadata": {
        "id": "6UU3Byju3STn"
      },
      "id": "6UU3Byju3STn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}